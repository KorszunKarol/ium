{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae9e15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "LISTINGS_PATH = \"./listings.csv\"\n",
    "CALENDAR_PATH = \"./calendar.csv\"\n",
    "REVIEWS_PATH = \"./reviews.csv\"\n",
    "LISTINGS_ID_COL = \"id\"\n",
    "CALENDAR_ID_COL = \"listing_id\"\n",
    "REVIEWS_ID_COL = \"listing_id\"\n",
    "\n",
    "\n",
    "print(f\"Loading listings from: {LISTINGS_PATH}\")\n",
    "df_listings = pd.read_csv(LISTINGS_PATH, low_memory=False)\n",
    "\n",
    "print(f\"Loading calendar from: {CALENDAR_PATH}\")\n",
    "\n",
    "df_calendar = pd.read_csv(CALENDAR_PATH)\n",
    "if \"date\" in df_calendar.columns:\n",
    "    df_calendar[\"date\"] = pd.to_datetime(df_calendar[\"date\"], errors=\"coerce\")\n",
    "\n",
    "print(f\"Loading reviews from: {REVIEWS_PATH}\")\n",
    "\n",
    "df_reviews = pd.read_csv(REVIEWS_PATH)\n",
    "if \"date\" in df_reviews.columns:\n",
    "    df_reviews[\"date\"] = pd.to_datetime(df_reviews[\"date\"], errors=\"coerce\")\n",
    "\n",
    "print(\"\\n--- Initial Data Shapes ---\")\n",
    "print(f\"Listings: {df_listings.shape}\")\n",
    "print(f\"Calendar: {df_calendar.shape}\")\n",
    "print(f\"Reviews: {df_reviews.shape}\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Listing ID Analysis ---\")\n",
    "\n",
    "id_stats = {}\n",
    "\n",
    "\n",
    "def calculate_id_stats(df, name, id_col):\n",
    "    if id_col not in df.columns:\n",
    "        print(f\"Warning: '{id_col}' column not found in {name}.\")\n",
    "        return {\n",
    "            \"Total Rows\": len(df),\n",
    "            f\"Rows with non-null {id_col}\": 0,\n",
    "            f\"Unique {id_col}s\": 0,\n",
    "            f\"% Non-Null {id_col}\": 0,\n",
    "        }\n",
    "\n",
    "    total_rows = len(df)\n",
    "    non_null_ids = df[id_col].notna().sum()\n",
    "    unique_ids = df[id_col].nunique()\n",
    "    stats = {\n",
    "        \"Total Rows\": total_rows,\n",
    "        f\"Rows with non-null {id_col}\": non_null_ids,\n",
    "        f\"Unique {id_col}s\": unique_ids,\n",
    "        f\"% Non-Null {id_col}\": (\n",
    "            round((non_null_ids / total_rows) * 100, 2) if total_rows > 0 else 0\n",
    "        ),\n",
    "    }\n",
    "    return stats\n",
    "\n",
    "\n",
    "id_stats[\"listings\"] = calculate_id_stats(df_listings, \"listings\", LISTINGS_ID_COL)\n",
    "id_stats[\"calendar\"] = calculate_id_stats(df_calendar, \"calendar\", CALENDAR_ID_COL)\n",
    "id_stats[\"reviews\"] = calculate_id_stats(df_reviews, \"reviews\", REVIEWS_ID_COL)\n",
    "\n",
    "stats_df = pd.DataFrame(id_stats).T\n",
    "print(stats_df)\n",
    "\n",
    "\n",
    "print(\"\\n--- Merge Simulation (Listings INNER JOIN Calendar) ---\")\n",
    "\n",
    "\n",
    "if LISTINGS_ID_COL in df_listings.columns and CALENDAR_ID_COL in df_calendar.columns:\n",
    "    listings_ids = (\n",
    "        pd.to_numeric(df_listings[LISTINGS_ID_COL], errors=\"coerce\").dropna().unique()\n",
    "    )\n",
    "    calendar_ids = (\n",
    "        pd.to_numeric(df_calendar[CALENDAR_ID_COL], errors=\"coerce\").dropna().unique()\n",
    "    )\n",
    "\n",
    "    df_listings_ids = pd.DataFrame({CALENDAR_ID_COL: listings_ids})\n",
    "    df_calendar_ids = pd.DataFrame({CALENDAR_ID_COL: calendar_ids})\n",
    "\n",
    "    merged_df = pd.merge(\n",
    "        df_listings_ids, df_calendar_ids, on=CALENDAR_ID_COL, how=\"inner\"\n",
    "    )\n",
    "\n",
    "    merged_unique_ids = merged_df[CALENDAR_ID_COL].nunique()\n",
    "    listings_unique_ids = len(listings_ids)\n",
    "    calendar_unique_ids = len(calendar_ids)\n",
    "\n",
    "    print(\n",
    "        f\"Unique valid listing_ids in listings (col '{LISTINGS_ID_COL}'): {listings_unique_ids}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Unique valid listing_ids in calendar (col '{CALENDAR_ID_COL}'): {calendar_unique_ids}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Unique listing_ids present in BOTH listings and calendar (after cleaning): {merged_unique_ids}\"\n",
    "    )\n",
    "\n",
    "    if listings_unique_ids > 0:\n",
    "        percentage_retained = round((merged_unique_ids / listings_unique_ids) * 100, 2)\n",
    "        print(\n",
    "            f\"Percentage of unique listings retained after merge: {percentage_retained}%\"\n",
    "        )\n",
    "    else:\n",
    "        print(\n",
    "            \"Cannot calculate retention percentage, no valid unique listings found in listings df.\"\n",
    "        )\n",
    "else:\n",
    "    print(\n",
    "        f\"Skipping merge simulation: ID column missing ('{LISTINGS_ID_COL}' in listings or '{CALENDAR_ID_COL}' in calendar).\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98abd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "if \"df_listings\" not in locals():\n",
    "    print(\"Error: df_listings not found. Please run the previous cell first.\")\n",
    "else:\n",
    "    NEIGHBORHOOD_COL = \"neighbourhood_cleansed\"\n",
    "\n",
    "    if NEIGHBORHOOD_COL not in df_listings.columns:\n",
    "        print(f\"Error: Column '{NEIGHBORHOOD_COL}' not found in listings dataframe.\")\n",
    "    else:\n",
    "        total_listings = len(df_listings)\n",
    "        missing_neighborhoods = df_listings[NEIGHBORHOOD_COL].isna().sum()\n",
    "        percentage_missing = (\n",
    "            round((missing_neighborhoods / total_listings) * 100, 2)\n",
    "            if total_listings > 0\n",
    "            else 0\n",
    "        )\n",
    "\n",
    "        print(f\"\\n--- Missing Neighborhood Analysis ('{NEIGHBORHOOD_COL}') ---\")\n",
    "        print(f\"Total listings: {total_listings}\")\n",
    "        print(f\"Listings missing '{NEIGHBORHOOD_COL}': {missing_neighborhoods}\")\n",
    "        print(f\"Percentage missing: {percentage_missing}%\")\n",
    "\n",
    "        print(f\"\\nPlotting distribution of listings per '{NEIGHBORHOOD_COL}'...\")\n",
    "\n",
    "        neighborhood_counts = (\n",
    "            df_listings[NEIGHBORHOOD_COL].fillna(\"Missing\").value_counts()\n",
    "        )\n",
    "\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.barplot(\n",
    "            y=neighborhood_counts.index, x=neighborhood_counts.values, palette=\"viridis\"\n",
    "        )\n",
    "\n",
    "        plt.title(f'Number of Listings per Neighborhood (\"{NEIGHBORHOOD_COL}\")')\n",
    "        plt.xlabel(\"Number of Listings\")\n",
    "        plt.ylabel(\"Neighborhood\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        print(\"\\nTop 10 Neighborhoods by Listing Count (including Missing):\")\n",
    "        print(neighborhood_counts.head(10))\n",
    "\n",
    "        if \"latitude\" in df_listings.columns and \"longitude\" in df_listings.columns:\n",
    "            missing_lat = df_listings[\"latitude\"].isna().sum()\n",
    "            missing_lon = df_listings[\"longitude\"].isna().sum()\n",
    "            print(\"\\n--- Lat/Lon Completeness Check ---\")\n",
    "            print(\n",
    "                f\"Missing latitude: {missing_lat} ({round(missing_lat * 100 / total_listings, 2)}%)\"\n",
    "            )\n",
    "            print(\n",
    "                f\"Missing longitude: {missing_lon} ({round(missing_lon * 100 / total_listings, 2)}%)\"\n",
    "            )\n",
    "\n",
    "            if missing_neighborhoods > 0:\n",
    "                missing_neigh_df = df_listings[df_listings[NEIGHBORHOOD_COL].isna()]\n",
    "                missing_lat_in_missing_neigh = missing_neigh_df[\"latitude\"].isna().sum()\n",
    "                missing_lon_in_missing_neigh = (\n",
    "                    missing_neigh_df[\"longitude\"].isna().sum()\n",
    "                )\n",
    "                print(\n",
    "                    f\"  - Among listings missing neighborhood: {missing_lat_in_missing_neigh} missing latitude ({round(missing_lat_in_missing_neigh * 100 / missing_neighborhoods, 2)}%)\"\n",
    "                )\n",
    "                print(\n",
    "                    f\"  - Among listings missing neighborhood: {missing_lon_in_missing_neigh} missing longitude ({round(missing_lon_in_missing_neigh * 100 / missing_neighborhoods, 2)}%)\"\n",
    "                )\n",
    "            else:\n",
    "                print(\"No listings are missing neighborhood data.\")\n",
    "\n",
    "        else:\n",
    "            print(\"\\nLatitude/Longitude columns not found for imputation check.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89863693",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "print(\"\\n--- Geospatial Distribution of Missing Neighborhoods ---\")\n",
    "\n",
    "if (\n",
    "    NEIGHBORHOOD_COL in df_listings.columns\n",
    "    and \"latitude\" in df_listings.columns\n",
    "    and \"longitude\" in df_listings.columns\n",
    "):\n",
    "    listings_with_coords = df_listings.dropna(subset=[\"latitude\", \"longitude\"])\n",
    "    listings_missing_neigh = listings_with_coords[\n",
    "        listings_with_coords[NEIGHBORHOOD_COL].isna()\n",
    "    ]\n",
    "    listings_valid_neigh = listings_with_coords[\n",
    "        listings_with_coords[NEIGHBORHOOD_COL].notna()\n",
    "    ]\n",
    "\n",
    "    num_missing_plot = len(listings_missing_neigh)\n",
    "\n",
    "    if num_missing_plot > 0:\n",
    "        print(\n",
    "            f\"Plotting {num_missing_plot} listings with coordinates but missing neighborhood...\"\n",
    "        )\n",
    "\n",
    "        plt.figure(figsize=(10, 10))\n",
    "\n",
    "        sns.scatterplot(\n",
    "            data=listings_valid_neigh,\n",
    "            x=\"longitude\",\n",
    "            y=\"latitude\",\n",
    "            color=\"blue\",\n",
    "            alpha=0.5,\n",
    "            s=15,\n",
    "            label=\"Valid Neighborhood\",\n",
    "        )\n",
    "\n",
    "        sns.scatterplot(\n",
    "            data=listings_missing_neigh,\n",
    "            x=\"longitude\",\n",
    "            y=\"latitude\",\n",
    "            color=\"red\",\n",
    "            alpha=0.5,\n",
    "            s=15,\n",
    "            label=\"Missing Neighborhood\",\n",
    "        )\n",
    "\n",
    "        plt.title(\"Spatial Distribution of Listings with Missing Neighborhood Data\")\n",
    "        plt.xlabel(\"Longitude\")\n",
    "        plt.ylabel(\"Latitude\")\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\n",
    "            \"No listings found with coordinates but missing neighborhood data to plot.\"\n",
    "        )\n",
    "\n",
    "else:\n",
    "    print(\n",
    "        \"Skipping geospatial plot: Required columns ('neighbourhood_cleansed', 'latitude', 'longitude') not available.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d94cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "print(\"--- Cleaning and Analyzing Calendar Price ---\")\n",
    "\n",
    "\n",
    "def clean_price(price_str):\n",
    "    if pd.isna(price_str):\n",
    "        return np.nan\n",
    "\n",
    "    if isinstance(price_str, str):\n",
    "        price_clean = re.sub(r\"[^0-9.]\", \"\", price_str)\n",
    "        try:\n",
    "            return float(price_clean)\n",
    "        except ValueError:\n",
    "            return np.nan\n",
    "    else:\n",
    "        return price_str\n",
    "\n",
    "\n",
    "if df_calendar[\"price\"].dtype == \"object\":\n",
    "    print(\"Cleaning price column...\")\n",
    "    df_calendar[\"price_numeric\"] = df_calendar[\"price\"].apply(clean_price)\n",
    "else:\n",
    "    print(\"Price column already numeric.\")\n",
    "    df_calendar[\"price_numeric\"] = df_calendar[\"price\"]\n",
    "\n",
    "\n",
    "price_stats = df_calendar[\"price_numeric\"].describe()\n",
    "print(\"\\nPrice Statistics:\")\n",
    "print(price_stats)\n",
    "\n",
    "\n",
    "q1 = price_stats[\"25%\"]\n",
    "q3 = price_stats[\"75%\"]\n",
    "iqr = q3 - q1\n",
    "price_lower_bound = q1 - 1.5 * iqr\n",
    "price_upper_bound = q3 + 1.5 * iqr\n",
    "price_outliers = df_calendar[\n",
    "    (df_calendar[\"price_numeric\"] < price_lower_bound)\n",
    "    | (df_calendar[\"price_numeric\"] > price_upper_bound)\n",
    "]\n",
    "\n",
    "print(\n",
    "    f\"\\nPrice Outliers Detected: {len(price_outliers)} rows ({round(len(price_outliers) * 100 / len(df_calendar), 2)}% of total)\"\n",
    ")\n",
    "print(\n",
    "    f\"Price Range for non-outliers: £{price_lower_bound:.2f} to £{price_upper_bound:.2f}\"\n",
    ")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df_calendar[\"price_numeric\"].dropna(), bins=50, kde=True)\n",
    "plt.title(\"Distribution of Daily Prices (with outliers)\")\n",
    "plt.xlabel(\"Price\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlim(0, price_stats[\"75%\"] * 3)\n",
    "plt.axvline(\n",
    "    price_upper_bound,\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    label=f\"Upper Bound (£{price_upper_bound:.2f})\",\n",
    ")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"\\n--- Availability Flag Analysis ---\")\n",
    "\n",
    "\n",
    "available_values = df_calendar[\"available\"].value_counts(dropna=False)\n",
    "print(\"Values in 'available' column:\")\n",
    "print(available_values)\n",
    "\n",
    "\n",
    "missing_available = df_calendar[\"available\"].isna().sum()\n",
    "missing_available_pct = round(missing_available * 100 / len(df_calendar), 2)\n",
    "print(f\"Missing 'available' values: {missing_available} ({missing_available_pct}%)\")\n",
    "\n",
    "\n",
    "if \"available_numeric\" not in df_calendar.columns:\n",
    "    df_calendar[\"available_numeric\"] = df_calendar[\"available\"].map({\"t\": 1, \"f\": 0})\n",
    "\n",
    "\n",
    "print(\"\\n--- Observation Period Analysis ---\")\n",
    "\n",
    "\n",
    "if df_calendar[\"date\"].dtype == \"<M8[ns]\":\n",
    "    date_ranges = (\n",
    "        df_calendar.groupby(\"listing_id\")[\"date\"].agg([\"min\", \"max\"]).reset_index()\n",
    "    )\n",
    "    date_ranges[\"observation_days\"] = (\n",
    "        date_ranges[\"max\"] - date_ranges[\"min\"]\n",
    "    ).dt.days + 1\n",
    "\n",
    "    obs_days_stats = date_ranges[\"observation_days\"].describe()\n",
    "    print(\"\\nObservation Period Statistics (days):\")\n",
    "    print(obs_days_stats)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(date_ranges[\"observation_days\"], bins=50, kde=True)\n",
    "    plt.title(\"Distribution of Observation Period Length per Listing\")\n",
    "    plt.xlabel(\"Observation Period (days)\")\n",
    "    plt.ylabel(\"Number of Listings\")\n",
    "    plt.axvline(365, color=\"red\", linestyle=\"--\", label=\"Full Year (365 days)\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    short_obs = date_ranges[date_ranges[\"observation_days\"] < 30]\n",
    "    print(\n",
    "        f\"\\nListings with very short observation periods (<30 days): {len(short_obs)} ({round(len(short_obs) * 100 / len(date_ranges), 2)}% of listings)\"\n",
    "    )\n",
    "\n",
    "    listing_counts = (\n",
    "        df_calendar.groupby(\"listing_id\").size().reset_index(name=\"data_points\")\n",
    "    )\n",
    "    merged_obs = pd.merge(date_ranges, listing_counts, on=\"listing_id\")\n",
    "\n",
    "    merged_obs[\"points_per_day\"] = (\n",
    "        merged_obs[\"data_points\"] / merged_obs[\"observation_days\"]\n",
    "    )\n",
    "    print(\"\\nData Points per Day Statistics:\")\n",
    "    print(merged_obs[\"points_per_day\"].describe())\n",
    "\n",
    "    complete_coverage = merged_obs[merged_obs[\"points_per_day\"] >= 0.95].shape[0]\n",
    "    print(\n",
    "        f\"Listings with near-complete daily coverage (≥0.95 points/day): {complete_coverage} ({round(complete_coverage * 100 / len(merged_obs), 2)}%)\"\n",
    "    )\n",
    "\n",
    "    if \"available_numeric\" in df_calendar.columns:\n",
    "        print(\"\\n--- Sample Occupancy Rate Calculation ---\")\n",
    "        occupancy = (\n",
    "            df_calendar.groupby(\"listing_id\")[\"available_numeric\"]\n",
    "            .agg(\n",
    "                total_days=\"count\",\n",
    "                available_days=lambda x: (x == 1).sum(),\n",
    "                booked_days=lambda x: (x == 0).sum(),\n",
    "            )\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "        occupancy[\"occupancy_rate\"] = occupancy[\"booked_days\"] / occupancy[\"total_days\"]\n",
    "        print(\"\\nOccupancy Rate Statistics:\")\n",
    "        print(occupancy[\"occupancy_rate\"].describe())\n",
    "\n",
    "        occupancy_with_days = pd.merge(occupancy, date_ranges, on=\"listing_id\")\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.scatter(\n",
    "            occupancy_with_days[\"observation_days\"],\n",
    "            occupancy_with_days[\"occupancy_rate\"],\n",
    "            alpha=0.5,\n",
    "            s=10,\n",
    "        )\n",
    "        plt.title(\"Occupancy Rate vs. Observation Period\")\n",
    "        plt.xlabel(\"Observation Period (days)\")\n",
    "        plt.ylabel(\"Occupancy Rate\")\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.show()\n",
    "\n",
    "        corr = (\n",
    "            occupancy_with_days[[\"observation_days\", \"occupancy_rate\"]]\n",
    "            .corr()\n",
    "            .iloc[0, 1]\n",
    "        )\n",
    "        print(\n",
    "            f\"\\nCorrelation between observation period and occupancy rate: {corr:.4f}\"\n",
    "        )\n",
    "\n",
    "        if abs(corr) > 0.1:\n",
    "            print(\n",
    "                \"SIGNIFICANT CORRELATION: Observation period length may be biasing occupancy calculations.\"\n",
    "            )\n",
    "        else:\n",
    "            print(\n",
    "                \"Low correlation: Observation period length does not appear to significantly bias occupancy calculations.\"\n",
    "            )\n",
    "else:\n",
    "    print(\"Date column not in datetime format. Skipping observation period analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db42fc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "print(\"\\n--- Distribution of Calculated Occupancy Rates ---\")\n",
    "\n",
    "\n",
    "if (\n",
    "    \"occupancy\" in locals()\n",
    "    and isinstance(occupancy, pd.DataFrame)\n",
    "    and \"occupancy_rate\" in occupancy.columns\n",
    "):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(occupancy[\"occupancy_rate\"], bins=50, kde=True)\n",
    "    plt.title(\"Distribution of Calculated Occupancy Rate per Listing\")\n",
    "    plt.xlabel(\"Occupancy Rate\")\n",
    "    plt.ylabel(\"Number of Listings\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "    zero_occ = (occupancy[\"occupancy_rate\"] == 0).sum()\n",
    "    full_occ = (occupancy[\"occupancy_rate\"] == 1).sum()\n",
    "    print(f\"Listings with 0% calculated occupancy: {zero_occ}\")\n",
    "    print(f\"Listings with 100% calculated occupancy: {full_occ}\")\n",
    "\n",
    "else:\n",
    "    print(\n",
    "        \"Skipping occupancy distribution plot: 'occupancy' DataFrame not found or missing 'occupancy_rate' column.\"\n",
    "    )\n",
    "    print(\"Ensure the previous parts of Task 3 executed correctly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a639a887",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "KEY_LISTING_FEATURES = [\n",
    "    \"id\",\n",
    "    \"neighbourhood_cleansed\",\n",
    "    \"property_type\",\n",
    "    \"room_type\",\n",
    "    \"accommodates\",\n",
    "    \"bathrooms\",\n",
    "    \"bedrooms\",\n",
    "    \"beds\",\n",
    "    \"price\",\n",
    "    \"latitude\",\n",
    "    \"longitude\",\n",
    "    \"review_scores_rating\",\n",
    "    \"review_scores_accuracy\",\n",
    "    \"review_scores_cleanliness\",\n",
    "    \"review_scores_checkin\",\n",
    "    \"review_scores_communication\",\n",
    "    \"review_scores_location\",\n",
    "    \"review_scores_value\",\n",
    "    \"number_of_reviews\",\n",
    "    \"reviews_per_month\",\n",
    "    \"availability_365\",\n",
    "]\n",
    "\n",
    "\n",
    "key_features_df = df_listings[KEY_LISTING_FEATURES].copy()\n",
    "\n",
    "\n",
    "print(\"--- Missing Value Analysis ---\")\n",
    "\n",
    "\n",
    "missing_percentages = key_features_df.isna().mean() * 100\n",
    "missing_percentages = missing_percentages.sort_values(ascending=False)\n",
    "\n",
    "\n",
    "missing_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Feature\": missing_percentages.index,\n",
    "        \"Missing %\": missing_percentages.values,\n",
    "        \"Non-Missing Count\": key_features_df.shape[0] - key_features_df.isna().sum(),\n",
    "        \"Total Count\": key_features_df.shape[0],\n",
    "    }\n",
    ")\n",
    "print(\"\\nMissing Values by Feature:\")\n",
    "print(missing_df)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(y=missing_percentages.index, x=missing_percentages, palette=\"viridis\")\n",
    "plt.title(\"Percentage of Missing Values by Feature\")\n",
    "plt.xlabel(\"Missing Percentage (%)\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"\\n--- Numerical Feature Distributions ---\")\n",
    "\n",
    "\n",
    "numerical_features = key_features_df.select_dtypes(\n",
    "    include=[\"float64\", \"int64\"]\n",
    ").columns.tolist()\n",
    "\n",
    "\n",
    "if \"price\" in key_features_df.columns and key_features_df[\"price\"].dtype == \"object\":\n",
    "\n",
    "    def clean_listing_price(price_str):\n",
    "        if pd.isna(price_str):\n",
    "            return np.nan\n",
    "\n",
    "        if isinstance(price_str, str):\n",
    "            price_clean = re.sub(r\"[^0-9.]\", \"\", price_str)\n",
    "            try:\n",
    "                return float(price_clean)\n",
    "            except ValueError:\n",
    "                return np.nan\n",
    "        else:\n",
    "            return price_str\n",
    "\n",
    "    key_features_df[\"price_numeric\"] = key_features_df[\"price\"].apply(\n",
    "        clean_listing_price\n",
    "    )\n",
    "    if \"price\" in numerical_features:\n",
    "        numerical_features.remove(\"price\")\n",
    "    numerical_features.append(\"price_numeric\")\n",
    "\n",
    "\n",
    "print(\"Plotting distributions for key numerical features...\")\n",
    "for column in [\n",
    "    \"accommodates\",\n",
    "    \"bedrooms\",\n",
    "    \"beds\",\n",
    "    \"bathrooms\",\n",
    "    \"review_scores_rating\",\n",
    "    \"number_of_reviews\",\n",
    "    \"reviews_per_month\",\n",
    "]:\n",
    "    if column in numerical_features:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.histplot(key_features_df[column].dropna(), kde=True)\n",
    "        plt.title(f\"Distribution of {column}\")\n",
    "        plt.xlabel(column)\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        print(f\"\\nStatistics for {column}:\")\n",
    "        print(key_features_df[column].describe())\n",
    "\n",
    "\n",
    "if \"price_numeric\" in numerical_features:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    q3 = key_features_df[\"price_numeric\"].quantile(0.75)\n",
    "    sns.histplot(key_features_df[\"price_numeric\"].dropna(), kde=True)\n",
    "    plt.title(\"Distribution of Listing Price\")\n",
    "    plt.xlabel(\"Price\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.xlim(0, q3 * 3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\nStatistics for listing price:\")\n",
    "    print(key_features_df[\"price_numeric\"].describe())\n",
    "\n",
    "\n",
    "print(\"\\n--- Categorical Feature Distributions ---\")\n",
    "\n",
    "\n",
    "categorical_features = [\"property_type\", \"room_type\"]\n",
    "for feature in categorical_features:\n",
    "    if feature in key_features_df.columns:\n",
    "        value_counts = key_features_df[feature].value_counts().reset_index()\n",
    "        value_counts.columns = [feature, \"Count\"]\n",
    "\n",
    "        value_counts[\"Percentage\"] = (\n",
    "            value_counts[\"Count\"] / value_counts[\"Count\"].sum() * 100\n",
    "        )\n",
    "\n",
    "        print(f\"\\nValue counts for {feature}:\")\n",
    "        print(value_counts)\n",
    "\n",
    "        top_n = min(15, len(value_counts))\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.barplot(\n",
    "            data=value_counts.head(top_n), y=feature, x=\"Count\", palette=\"viridis\"\n",
    "        )\n",
    "        plt.title(f\"Top {top_n} Categories for {feature}\")\n",
    "        plt.xlabel(\"Count\")\n",
    "        plt.ylabel(feature)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "print(\"\\n--- Correlation Analysis ---\")\n",
    "\n",
    "\n",
    "correlation_features = [f for f in numerical_features if f != \"id\"]\n",
    "if correlation_features:\n",
    "    corr_matrix = key_features_df[correlation_features].corr().round(2)\n",
    "\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "    sns.heatmap(\n",
    "        corr_matrix,\n",
    "        annot=True,\n",
    "        mask=mask,\n",
    "        cmap=\"coolwarm\",\n",
    "        center=0,\n",
    "        linewidths=0.5,\n",
    "        cbar_kws={\"shrink\": 0.8},\n",
    "    )\n",
    "    plt.title(\"Correlation Matrix of Numerical Features\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    strong_correlations = []\n",
    "    for i in range(len(correlation_features)):\n",
    "        for j in range(i + 1, len(correlation_features)):\n",
    "            if abs(corr_matrix.iloc[i, j]) > 0.5:\n",
    "                strong_correlations.append(\n",
    "                    {\n",
    "                        \"Feature 1\": correlation_features[i],\n",
    "                        \"Feature 2\": correlation_features[j],\n",
    "                        \"Correlation\": corr_matrix.iloc[i, j],\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    if strong_correlations:\n",
    "        print(\"\\nStrong Correlations (|correlation| > 0.5):\")\n",
    "        strong_corr_df = pd.DataFrame(strong_correlations)\n",
    "        print(strong_corr_df.sort_values(\"Correlation\", key=abs, ascending=False))\n",
    "    else:\n",
    "        print(\"\\nNo strong correlations found between numerical features.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c138b9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "print(\"\\n--- Advanced Missing Value Patterns (missingno) ---\")\n",
    "\n",
    "try:\n",
    "    import missingno as msno\n",
    "\n",
    "    print(\"Visualizing missing value matrix...\")\n",
    "    msno.matrix(key_features_df)\n",
    "    plt.title(\"Missing Value Matrix (Listings Key Features)\", fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\nVisualizing missing value heatmap...\")\n",
    "    msno.heatmap(key_features_df)\n",
    "    plt.title(\"Missing Value Correlation Heatmap (Listings Key Features)\", fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "except ImportError:\n",
    "    print(\"\\nSkipping missingno plots: library 'missingno' not installed.\")\n",
    "    print(\"Install using: pip install missingno\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred during missingno plotting: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea697bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "print(\"\\n--- Distribution of Occupancy Rate Discrepancy ---\")\n",
    "\n",
    "\n",
    "if (\n",
    "    \"avail_comparison\" in locals()\n",
    "    and isinstance(avail_comparison, pd.DataFrame)\n",
    "    and \"abs_diff\" in avail_comparison.columns\n",
    "):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(avail_comparison[\"abs_diff\"], bins=40, kde=False)\n",
    "    plt.title(\"Distribution of Absolute Difference between Occupancy Measures\")\n",
    "    plt.xlabel(\"Absolute Difference (Implied vs. Calculated Occupancy Rate)\")\n",
    "    plt.ylabel(\"Number of Listings\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "    low_diff = (avail_comparison[\"abs_diff\"] < 0.05).sum()\n",
    "    low_diff_pct = round(low_diff * 100 / len(avail_comparison), 2)\n",
    "    print(\n",
    "        f\"Listings with very low discrepancy (< 0.05 or 5%): {low_diff} ({low_diff_pct}%)\"\n",
    "    )\n",
    "else:\n",
    "    print(\n",
    "        \"Skipping discrepancy histogram: 'avail_comparison' DataFrame not found or missing 'abs_diff' column.\"\n",
    "    )\n",
    "    print(\"Ensure the previous parts of Task 5 executed correctly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd75a585",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "print(\"--- Review Score Consistency Check ---\")\n",
    "\n",
    "\n",
    "if \"numerical_review\" in df_reviews.columns and REVIEWS_ID_COL in df_reviews.columns:\n",
    "    avg_reviews = (\n",
    "        df_reviews.dropna(subset=[REVIEWS_ID_COL, \"numerical_review\"])\n",
    "        .groupby(REVIEWS_ID_COL)[\"numerical_review\"]\n",
    "        .agg([\"mean\", \"count\"])\n",
    "        .reset_index()\n",
    "    )\n",
    "    avg_reviews.columns = [REVIEWS_ID_COL, \"avg_numerical_review\", \"review_count\"]\n",
    "\n",
    "    if (\n",
    "        \"review_scores_rating\" in df_listings.columns\n",
    "        and LISTINGS_ID_COL in df_listings.columns\n",
    "    ):\n",
    "        listings_reviews = df_listings[[LISTINGS_ID_COL, \"review_scores_rating\"]].copy()\n",
    "        listings_reviews.rename(columns={LISTINGS_ID_COL: REVIEWS_ID_COL}, inplace=True)\n",
    "\n",
    "        review_comparison = pd.merge(\n",
    "            listings_reviews, avg_reviews, on=REVIEWS_ID_COL, how=\"inner\"\n",
    "        )\n",
    "\n",
    "        print(f\"Successfully merged reviews for {len(review_comparison)} listings\")\n",
    "        print(\"\\nReview scores statistics:\")\n",
    "        review_stats = review_comparison[\n",
    "            [\"review_scores_rating\", \"avg_numerical_review\"]\n",
    "        ].describe()\n",
    "        print(review_stats)\n",
    "\n",
    "        review_comparison[\"abs_diff\"] = abs(\n",
    "            review_comparison[\"review_scores_rating\"]\n",
    "            - review_comparison[\"avg_numerical_review\"] * 2\n",
    "        )\n",
    "        review_corr = (\n",
    "            review_comparison[[\"review_scores_rating\", \"avg_numerical_review\"]]\n",
    "            .corr()\n",
    "            .iloc[0, 1]\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"\\nCorrelation between listing review score and average numerical review: {review_corr:.4f}\"\n",
    "        )\n",
    "        print(\"\\nAbsolute difference statistics:\")\n",
    "        print(review_comparison[\"abs_diff\"].describe())\n",
    "\n",
    "        large_diff_count = (review_comparison[\"abs_diff\"] > 1).sum()\n",
    "        large_diff_pct = round(large_diff_count * 100 / len(review_comparison), 2)\n",
    "        print(\n",
    "            f\"\\nListings with large review score discrepancy (>1 point): {large_diff_count} ({large_diff_pct}%)\"\n",
    "        )\n",
    "\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.scatter(\n",
    "            review_comparison[\"avg_numerical_review\"] * 2,\n",
    "            review_comparison[\"review_scores_rating\"],\n",
    "            alpha=0.5,\n",
    "            s=10,\n",
    "        )\n",
    "        plt.plot([0, 10], [0, 10], color=\"red\", linestyle=\"--\")\n",
    "        plt.title(\"Listing Review Score vs Average Numerical Review\")\n",
    "        plt.xlabel(\"Average Numerical Review (scaled to 0-10 range)\")\n",
    "        plt.ylabel(\"Review Score Rating (0-10)\")\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        reliable_reviews = review_comparison[\n",
    "            review_comparison[\"review_count\"] >= 5\n",
    "        ].copy()\n",
    "        if len(reliable_reviews) > 0:\n",
    "            reliable_corr = (\n",
    "                reliable_reviews[[\"review_scores_rating\", \"avg_numerical_review\"]]\n",
    "                .corr()\n",
    "                .iloc[0, 1]\n",
    "            )\n",
    "            print(\n",
    "                f\"\\nCorrelation for listings with 5+ reviews ({len(reliable_reviews)} listings): {reliable_corr:.4f}\"\n",
    "            )\n",
    "\n",
    "    else:\n",
    "        print(\n",
    "            \"Unable to check review score consistency: 'review_scores_rating' not found in listings data\"\n",
    "        )\n",
    "else:\n",
    "    print(\n",
    "        \"Unable to calculate average numerical reviews: required columns not found in reviews data\"\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"\\n--- Availability vs. Occupancy Consistency Check ---\")\n",
    "\n",
    "\n",
    "occupancy_from_calendar_exists = False\n",
    "try:\n",
    "    if \"occupancy\" not in locals() and \"available_numeric\" in df_calendar.columns:\n",
    "        occupancy = (\n",
    "            df_calendar.groupby(CALENDAR_ID_COL)[\"available_numeric\"]\n",
    "            .agg(\n",
    "                total_days=\"count\",\n",
    "                available_days=lambda x: (x == 1).sum(),\n",
    "                booked_days=lambda x: (x == 0).sum(),\n",
    "            )\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "        occupancy[\"occupancy_rate\"] = occupancy[\"booked_days\"] / occupancy[\"total_days\"]\n",
    "        occupancy_from_calendar_exists = True\n",
    "    elif \"occupancy\" in locals():\n",
    "        occupancy_from_calendar_exists = True\n",
    "except Exception as e:\n",
    "    print(f\"Error calculating occupancy: {e}\")\n",
    "    occupancy_from_calendar_exists = False\n",
    "\n",
    "\n",
    "if \"availability_365\" in df_listings.columns and LISTINGS_ID_COL in df_listings.columns:\n",
    "    listings_avail = df_listings[[LISTINGS_ID_COL, \"availability_365\"]].copy()\n",
    "\n",
    "    listings_avail[\"availability_rate\"] = listings_avail[\"availability_365\"] / 365\n",
    "\n",
    "    if occupancy_from_calendar_exists:\n",
    "        listings_avail.rename(columns={LISTINGS_ID_COL: CALENDAR_ID_COL}, inplace=True)\n",
    "\n",
    "        avail_comparison = pd.merge(\n",
    "            listings_avail, occupancy, on=CALENDAR_ID_COL, how=\"inner\"\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"Successfully merged availability data for {len(avail_comparison)} listings\"\n",
    "        )\n",
    "\n",
    "        avail_comparison[\"implied_occupancy\"] = (\n",
    "            1 - avail_comparison[\"availability_rate\"]\n",
    "        )\n",
    "\n",
    "        avail_comparison[\"abs_diff\"] = abs(\n",
    "            avail_comparison[\"implied_occupancy\"] - avail_comparison[\"occupancy_rate\"]\n",
    "        )\n",
    "        avail_corr = (\n",
    "            avail_comparison[[\"implied_occupancy\", \"occupancy_rate\"]].corr().iloc[0, 1]\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"\\nCorrelation between implied occupancy and calculated occupancy: {avail_corr:.4f}\"\n",
    "        )\n",
    "        print(\"\\nAbsolute difference statistics:\")\n",
    "        print(avail_comparison[\"abs_diff\"].describe())\n",
    "\n",
    "        large_diff_count = (avail_comparison[\"abs_diff\"] > 0.2).sum()\n",
    "        large_diff_pct = round(large_diff_count * 100 / len(avail_comparison), 2)\n",
    "        print(\n",
    "            f\"\\nListings with large occupancy discrepancy (>20%): {large_diff_count} ({large_diff_pct}%)\"\n",
    "        )\n",
    "\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.scatter(\n",
    "            avail_comparison[\"implied_occupancy\"],\n",
    "            avail_comparison[\"occupancy_rate\"],\n",
    "            alpha=0.5,\n",
    "            s=10,\n",
    "        )\n",
    "        plt.plot([0, 1], [0, 1], color=\"red\", linestyle=\"--\")\n",
    "        plt.title(\"Implied Occupancy (from availability_365) vs Calculated Occupancy\")\n",
    "        plt.xlabel(\"Implied Occupancy Rate (1 - availability_365/365)\")\n",
    "        plt.ylabel(\"Calculated Occupancy Rate (from calendar)\")\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.xlim(0, 1)\n",
    "        plt.ylim(0, 1)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    else:\n",
    "        print(\n",
    "            \"Unable to compare with calendar occupancy - occupancy data not calculated\"\n",
    "        )\n",
    "else:\n",
    "    print(\n",
    "        \"Unable to check availability consistency: 'availability_365' not found in listings data\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
